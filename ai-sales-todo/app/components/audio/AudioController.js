'use client'

import { useState, useRef, useEffect } from 'react'
import { Mic, MicOff, Play, Pause, Square, Volume2, Settings, AlertTriangle } from 'lucide-react'

export default function AudioController({ todos, onTodoComplete, similarityThreshold, onThresholdChange }) {
  const [isRecording, setIsRecording] = useState(false)
  const [isProcessing, setIsProcessing] = useState(false)
  const [audioLevel, setAudioLevel] = useState(0)
  const [transcription, setTranscription] = useState('')
  const [recentMatches, setRecentMatches] = useState([])
  const [recordingTime, setRecordingTime] = useState(0)
  const [showSettings, setShowSettings] = useState(false)

  const mediaRecorder = useRef(null)
  const audioContext = useRef(null)
  const analyzer = useRef(null)
  const dataArray = useRef(null)
  const animationFrame = useRef(null)
  const recordingTimer = useRef(null)

  useEffect(() => {
    return () => {
      if (animationFrame.current) {
        cancelAnimationFrame(animationFrame.current)
      }
      if (recordingTimer.current) {
        clearInterval(recordingTimer.current)
      }
      if (audioContext.current) {
        audioContext.current.close()
      }
    }
  }, [])

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      
      // Audio Context for visualization
      audioContext.current = new AudioContext()
      const source = audioContext.current.createMediaStreamSource(stream)
      analyzer.current = audioContext.current.createAnalyser()
      analyzer.current.fftSize = 256
      
      source.connect(analyzer.current)
      dataArray.current = new Uint8Array(analyzer.current.frequencyBinCount)
      
      // MediaRecorder for recording
      mediaRecorder.current = new MediaRecorder(stream)
      const audioChunks = []
      
      mediaRecorder.current.ondataavailable = (event) => {
        audioChunks.push(event.data)
      }
      
      mediaRecorder.current.onstop = async () => {
        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' })
        await processAudio(audioBlob)
        
        // Clean up
        stream.getTracks().forEach(track => track.stop())
        if (audioContext.current) {
          audioContext.current.close()
        }
      }
      
      mediaRecorder.current.start()
      setIsRecording(true)
      setRecordingTime(0)
      
      // Start timer
      recordingTimer.current = setInterval(() => {
        setRecordingTime(prev => prev + 1)
      }, 1000)
      
      // Start audio visualization
      visualizeAudio()
      
    } catch (error) {
      console.error('éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼:', error)
      alert('ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚')
    }
  }

  const stopRecording = () => {
    if (mediaRecorder.current && mediaRecorder.current.state === 'recording') {
      mediaRecorder.current.stop()
    }
    setIsRecording(false)
    setAudioLevel(0)
    
    if (recordingTimer.current) {
      clearInterval(recordingTimer.current)
    }
    if (animationFrame.current) {
      cancelAnimationFrame(animationFrame.current)
    }
  }

  const visualizeAudio = () => {
    if (!analyzer.current || !dataArray.current) return
    
    analyzer.current.getByteFrequencyData(dataArray.current)
    
    // Calculate average audio level
    const average = dataArray.current.reduce((a, b) => a + b) / dataArray.current.length
    setAudioLevel(Math.min(100, (average / 255) * 100))
    
    if (isRecording) {
      animationFrame.current = requestAnimationFrame(visualizeAudio)
    }
  }

  const processAudio = async (audioBlob) => {
    setIsProcessing(true)
    setTranscription('')
    
    try {
      // Web Speech API ã¾ãŸã¯ Google Gemini APIã«ã‚ˆã‚‹å®Ÿéš›ã®éŸ³å£°èªè­˜å‡¦ç†
      const formData = new FormData()
      formData.append('audio', audioBlob)
      formData.append('duration', recordingTime + 's')
      
      const response = await fetch('/api/voice', {
        method: 'POST',
        body: formData
      })
      
      if (!response.ok) {
        throw new Error(`éŸ³å£°å‡¦ç†API ã‚¨ãƒ©ãƒ¼: ${response.status}`)
      }
      
      const result = await response.json()
      const transcribedText = result.transcription
      
      setTranscription(transcribedText)
      console.log('[AudioController] éŸ³å£°èªè­˜çµæœ:', transcribedText)
      
      // é«˜ç²¾åº¦ãªé¡ä¼¼åº¦è¨ˆç®—ã‚’ä½¿ç”¨ã—ã¦ToDoé …ç›®ã¨ã®ãƒãƒƒãƒãƒ³ã‚°ã‚’å®Ÿè¡Œ
      await checkTodoMatches(transcribedText)
      setIsProcessing(false)
      
    } catch (error) {
      console.error('éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼:', error)
      setTranscription('éŸ³å£°å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ')
      setIsProcessing(false)
    }
  }

  const checkTodoMatches = async (text) => {
    if (!text || !todos || todos.length === 0) {
      return
    }
    
    const incompleteTodos = todos.filter(todo => !todo.completed)
    if (incompleteTodos.length === 0) {
      console.log('[AudioController] æœªå®Œäº†ã®ToDoãŒã‚ã‚Šã¾ã›ã‚“')
      return
    }
    
    console.log(`[AudioController] ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ToDoç…§åˆé–‹å§‹: "${text}"`)
    
    try {
      // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
      const { processVoiceCompletion } = await import('../../../lib/realtimeUpdater')
      
      await processVoiceCompletion(
        text,
        incompleteTodos,
        similarityThreshold,
        (todoId, result) => {
          // å®Œäº†ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
          console.log(`[AudioController] ToDo #${todoId} ãŒãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ã«ã‚ˆã‚Šå®Œäº†ã—ã¾ã—ãŸ`)
          
          // UIã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
          if (onTodoComplete) {
            onTodoComplete(todoId)
          }
          
          // ãƒãƒƒãƒå±¥æ­´æ›´æ–°
          const matchData = {
            todo: incompleteTodos.find(t => t.id === todoId),
            similarity: result.apiResult?.metadata?.similarity || 0,
            matchedAt: new Date(),
            transcribedText: text,
            method: 'realtime_voice_completion'
          }
          
          setRecentMatches(prev => [matchData, ...prev.slice(0, 4)])
        }
      )
      
    } catch (error) {
      console.error('[AudioController] ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç…§åˆå‡¦ç†ã‚¨ãƒ©ãƒ¼:', error)
      
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®å‡¦ç†
      await fallbackTodoMatching(text, incompleteTodos)
    }
  }
  
  // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®å¾“æ¥å‡¦ç†
  const fallbackTodoMatching = async (text, incompleteTodos) => {
    console.log('[AudioController] ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç…§åˆå‡¦ç†å®Ÿè¡Œ')
    
    try {
      // é«˜ç²¾åº¦ãªé¡ä¼¼åº¦è¨ˆç®—ï¼ˆGoogle Gemini APIä½¿ç”¨ï¼‰
      const matchPromises = incompleteTodos.map(async (todo) => {
        try {
          // Google Gemini APIã‚’ä½¿ç”¨ã—ãŸæ„å‘³çš„é¡ä¼¼åº¦è¨ˆç®—
          const { calculateSimilarity } = await import('../../../lib/gemini')
          const similarity = await calculateSimilarity(todo.text, text)
          
          return {
            todo,
            similarity,
            matched: similarity >= similarityThreshold
          }
        } catch (error) {
          console.error(`ToDo #${todo.id} ã®é¡ä¼¼åº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼:`, error)
          // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“è¨ˆç®—
          const fallbackSimilarity = calculateFallbackSimilarity(todo.text, text)
          return {
            todo,
            similarity: fallbackSimilarity,
            matched: fallbackSimilarity >= similarityThreshold,
            fallback: true
          }
        }
      })
      
      const results = await Promise.all(matchPromises)
      const matches = results.filter(result => result.matched)
      
      if (matches.length > 0) {
        console.log(`[AudioController] ${matches.length}å€‹ã®ãƒãƒƒãƒã‚’ç™ºè¦‹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ï¼‰`)
        
        // é¡ä¼¼åº¦é †ã«ã‚½ãƒ¼ãƒˆ
        matches.sort((a, b) => b.similarity - a.similarity)
        
        // ãƒãƒƒãƒã—ãŸToDoé …ç›®ã‚’è‡ªå‹•å®Œäº†
        for (const match of matches) {
          console.log(`  - ToDo #${match.todo.id}: "${match.todo.text}" (é¡ä¼¼åº¦: ${(match.similarity * 100).toFixed(1)}%${match.fallback ? ' - fallback' : ''})`)
          
          // APIçµŒç”±ã§ToDoå®Œäº†å‡¦ç†
          await updateTodoCompletion(match.todo.id, text, match.similarity)
          
          // UIã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
          if (onTodoComplete) {
            onTodoComplete(match.todo.id)
          }
        }
        
        // æœ€è¿‘ã®ãƒãƒƒãƒå±¥æ­´ã‚’æ›´æ–°
        const matchHistory = matches.map(match => ({
          todo: match.todo,
          similarity: match.similarity,
          matchedAt: new Date(),
          transcribedText: text,
          fallback: match.fallback || false,
          method: 'fallback_matching'
        }))
        
        setRecentMatches(prev => [...matchHistory, ...prev.slice(0, 4)])
      } else {
        console.log('[AudioController] ãƒãƒƒãƒã™ã‚‹ToDoãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ï¼‰')
      }
      
    } catch (error) {
      console.error('[AudioController] ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç…§åˆå‡¦ç†ã‚¨ãƒ©ãƒ¼:', error)
    }
  }
  
  // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ç°¡æ˜“é¡ä¼¼åº¦è¨ˆç®—
  const calculateFallbackSimilarity = (todoText, transcribedText) => {
    if (!todoText || !transcribedText) return 0
    
    const todoLower = todoText.toLowerCase()
    const transcribedLower = transcribedText.toLowerCase()
    
    // å®Œå…¨ä¸€è‡´ãƒã‚§ãƒƒã‚¯
    if (transcribedLower.includes(todoLower) || todoLower.includes(transcribedLower)) {
      return 0.9
    }
    
    // ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
    const todoWords = todoLower.split(/[\sã€ã€‚]+/).filter(word => word.length > 1)
    const transcribedWords = transcribedLower.split(/[\sã€ã€‚]+/).filter(word => word.length > 1)
    
    let matchCount = 0
    todoWords.forEach(todoWord => {
      if (transcribedWords.some(transWord => 
        transWord.includes(todoWord) || todoWord.includes(transWord)
      )) {
        matchCount++
      }
    })
    
    return todoWords.length > 0 ? Math.min(1, matchCount / todoWords.length) : 0
  }
  
  // APIçµŒç”±ã§ToDoå®Œäº†å‡¦ç†
  const updateTodoCompletion = async (todoId, transcribedText, similarity) => {
    try {
      const response = await fetch('/api/todos', {
        method: 'PUT',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          todoId: todoId,
          completed: true,
          completedBy: 'voice_recognition',
          transcribedText: transcribedText,
          similarity: similarity,
          completedAt: new Date().toISOString()
        })
      })
      
      if (!response.ok) {
        throw new Error(`ToDoå®Œäº†API ã‚¨ãƒ©ãƒ¼: ${response.status}`)
      }
      
      const result = await response.json()
      console.log(`[AudioController] ToDo #${todoId} å®Œäº†å‡¦ç†æˆåŠŸ:`, result)
      return result
      
    } catch (error) {
      console.error(`[AudioController] ToDo #${todoId} å®Œäº†å‡¦ç†ã‚¨ãƒ©ãƒ¼:`, error)
      throw error
    }
  }

  const formatTime = (seconds) => {
    const mins = Math.floor(seconds / 60)
    const secs = seconds % 60
    return `${mins}:${secs.toString().padStart(2, '0')}`
  }

  return (
    <div className="bg-white rounded-xl shadow-lg border border-gray-200">
      {/* Header */}
      <div className="p-4 border-b border-gray-200 bg-gradient-to-r from-purple-50 to-pink-50">
        <div className="flex items-center justify-between">
          <div className="flex items-center gap-3">
            <div className="p-2 bg-purple-100 rounded-full">
              <Volume2 className="w-5 h-5 text-purple-600" />
            </div>
            <div>
              <h3 className="font-semibold text-gray-900">éŸ³å£°å‡¦ç†ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«</h3>
              <p className="text-sm text-gray-600">
                å•†è«‡ä¸­ã®éŸ³å£°ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è§£æ
              </p>
            </div>
          </div>
          <button
            onClick={() => setShowSettings(!showSettings)}
            className="p-2 text-gray-500 hover:text-gray-700 transition-colors"
          >
            <Settings className="w-5 h-5" />
          </button>
        </div>
      </div>

      {/* Settings Panel */}
      {showSettings && (
        <div className="p-4 border-b border-gray-200 bg-gray-50">
          <div className="space-y-4">
            <div>
              <label className="block text-sm font-medium text-gray-700 mb-2">
                é¡ä¼¼åº¦åˆ¤å®šã®é–¾å€¤: {(similarityThreshold * 100).toFixed(0)}%
              </label>
              <div className="flex items-center gap-3">
                <span className="text-xs text-gray-500">å³æ ¼</span>
                <input
                  type="range"
                  min="0.3"
                  max="0.9"
                  step="0.1"
                  value={similarityThreshold}
                  onChange={(e) => onThresholdChange(parseFloat(e.target.value))}
                  className="flex-1 accent-purple-500"
                />
                <span className="text-xs text-gray-500">ç·©ã„</span>
              </div>
              <p className="text-xs text-gray-600 mt-1">
                å€¤ãŒå°ã•ã„ã»ã©ã€ã‚ˆã‚Šå³å¯†ã«ãƒãƒƒãƒãƒ³ã‚°ã—ã¾ã™
              </p>
            </div>
          </div>
        </div>
      )}

      {/* Main Controls */}
      <div className="p-6 space-y-6">
        {/* Recording Controls */}
        <div className="flex flex-col items-center space-y-4">
          <div className="relative">
            <button
              onClick={isRecording ? stopRecording : startRecording}
              disabled={isProcessing}
              className={`w-20 h-20 rounded-full flex items-center justify-center transition-all duration-300 shadow-lg ${
                isRecording
                  ? 'bg-red-500 hover:bg-red-600 text-white animate-pulse'
                  : isProcessing
                  ? 'bg-gray-400 text-white cursor-not-allowed'
                  : 'bg-blue-500 hover:bg-blue-600 text-white hover:shadow-xl'
              }`}
            >
              {isProcessing ? (
                <div className="w-8 h-8 border-2 border-white border-t-transparent rounded-full animate-spin" />
              ) : isRecording ? (
                <Square className="w-8 h-8" />
              ) : (
                <Mic className="w-8 h-8" />
              )}
            </button>
            
            {/* Audio Level Indicator */}
            {isRecording && (
              <div className="absolute inset-0 rounded-full border-4 border-red-300"
                style={{
                  transform: `scale(${1 + audioLevel / 200})`
                }}
              />
            )}
          </div>

          <div className="text-center">
            {isRecording ? (
              <div>
                <div className="text-lg font-semibold text-red-600">
                  éŒ²éŸ³ä¸­... {formatTime(recordingTime)}
                </div>
                <div className="text-sm text-gray-500">
                  ã‚¯ãƒªãƒƒã‚¯ã§åœæ­¢
                </div>
              </div>
            ) : isProcessing ? (
              <div>
                <div className="text-lg font-semibold text-blue-600">
                  éŸ³å£°å‡¦ç†ä¸­...
                </div>
                <div className="text-sm text-gray-500">
                  æ–‡å­—èµ·ã“ã—ã¨ToDoåˆ¤å®šã‚’å®Ÿè¡Œä¸­
                </div>
              </div>
            ) : (
              <div>
                <div className="text-lg font-semibold text-gray-700">
                  éŒ²éŸ³é–‹å§‹
                </div>
                <div className="text-sm text-gray-500">
                  ã‚¯ãƒªãƒƒã‚¯ã§éŒ²éŸ³ã‚’é–‹å§‹
                </div>
              </div>
            )}
          </div>
        </div>

        {/* Audio Level Visualization */}
        {isRecording && (
          <div className="space-y-2">
            <div className="flex justify-between text-sm text-gray-600">
              <span>éŸ³å£°ãƒ¬ãƒ™ãƒ«</span>
              <span>{audioLevel.toFixed(1)}%</span>
            </div>
            <div className="w-full bg-gray-200 rounded-full h-3">
              <div
                className="bg-gradient-to-r from-green-500 via-yellow-500 to-red-500 h-3 rounded-full transition-all duration-100"
                style={{ width: `${audioLevel}%` }}
              />
            </div>
          </div>
        )}

        {/* Recent Transcription */}
        {transcription && (
          <div className="space-y-2">
            <h4 className="text-sm font-medium text-gray-700">æœ€æ–°ã®æ–‡å­—èµ·ã“ã—:</h4>
            <div className="p-3 bg-blue-50 rounded-lg border border-blue-200">
              <p className="text-sm text-gray-800">{String(transcription)}</p>
            </div>
          </div>
        )}

        {/* Recent Matches */}
        {recentMatches.length > 0 && (
          <div className="space-y-3">
            <h4 className="text-sm font-medium text-gray-700 flex items-center gap-2">
              <AlertTriangle className="w-4 h-4 text-green-500" />
              æœ€è¿‘å®Œäº†ã—ãŸToDo:
            </h4>
            <div className="space-y-2">
              {recentMatches.slice(0, 3).map((match, index) => (
                <div key={index} className="p-3 bg-green-50 rounded-lg border border-green-200">
                  <div className="flex items-start justify-between">
                    <div className="flex-1">
                      <p className="text-sm font-medium text-gray-800">
                        {String(match.todo.text)}
                      </p>
                      <div className="flex items-center gap-2 mt-1">
                        <span className="text-xs text-green-600">
                          é¡ä¼¼åº¦: {(match.similarity * 100).toFixed(1)}%
                        </span>
                        <span className="text-xs text-gray-500">
                          {match.matchedAt.toLocaleTimeString()}
                        </span>
                      </div>
                    </div>
                  </div>
                </div>
              ))}
            </div>
          </div>
        )}

        {/* Status Info */}
        <div className="text-center text-sm text-gray-500 space-y-1">
          <p>ğŸ¤ 30ç§’é–“éš”ã§è‡ªå‹•çš„ã«éŸ³å£°ã‚’å‡¦ç†ã—ã¾ã™</p>
          <p>ğŸ¤– AIãŒToDoé …ç›®ã¨ã®é¡ä¼¼åº¦ã‚’è‡ªå‹•åˆ¤å®šã—ã¾ã™</p>
          <p>âš™ï¸ è¨­å®šãƒœã‚¿ãƒ³ã§åˆ¤å®šæ„Ÿåº¦ã‚’èª¿æ•´ã§ãã¾ã™</p>
        </div>
      </div>
    </div>
  )
}